"""
–°–∫—Ä–∏–ø—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python test_model.py              # 5 —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
    python test_model.py -n 10        # 10 –ø—Ä–∏–º–µ—Ä–æ–≤
    python test_model.py --errors     # –¢–æ–ª—å–∫–æ –æ—à–∏–±–æ—á–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    python test_model.py --class 0    # –¢–æ–ª—å–∫–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –æ—Ç–∑—ã–≤—ã
"""

import argparse
import numpy as np
import pandas as pd
import pickle
from pathlib import Path
from sklearn.model_selection import train_test_split

import sys
sys.path.insert(0, str(Path(__file__).parent / "src"))

from config import DATA_DIR, MODELS_DIR, TRAINING_CONFIG
from src.preprocessing import TextPreprocessor
from src.model import ReputationModel


def load_model_and_preprocessor():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞"""
    print("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
    with open(MODELS_DIR / "preprocessor.pkl", "rb") as f:
        preprocessor = pickle.load(f)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model = ReputationModel(
        vocab_size=preprocessor.get_vocab_size(),
        num_categories=preprocessor.get_num_categories()
    )
    model.load()
    
    return model, preprocessor


def get_test_data(preprocessor):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏"""
    df = pd.read_csv(DATA_DIR / "synthetic_dataset.csv")
    
    # –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º —Ç–æ –∂–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ, —á—Ç–æ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
    test_size = TRAINING_CONFIG["test_split"]
    _, test_df = train_test_split(
        df, 
        test_size=test_size,
        random_state=42,
        stratify=df["sentiment_class"]
    )
    
    return test_df


def predict_single(model, preprocessor, text, rating, category):
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞"""
    df = pd.DataFrame({
        "review_text": [text],
        "rating": [rating],
        "category": [category],
        "subject_id": ["TEST"],
        "sentiment_class": [0],
        "reputation_index": [0]
    })
    
    X_text, X_rating, X_category, _, _ = preprocessor.transform(df)
    class_probs, rep_index = model.predict(X_text, X_rating, X_category)
    
    return class_probs[0], rep_index[0][0]


def display_prediction(row, pred_class, pred_probs, pred_index):
    """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
    labels = ["–Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è", "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è", "–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è"]
    true_label = labels[row["sentiment_class"]]
    pred_label = labels[pred_class]
    
    is_correct = row["sentiment_class"] == pred_class
    status = "‚úÖ" if is_correct else "‚ùå"
    
    print("\n" + "‚ïê" * 70)
    print(f"üìù –¢–µ–∫—Å—Ç: {row['review_text']}")
    print(f"‚≠ê –û—Ü–µ–Ω–∫–∞: {row['rating']}/5 | üì¶ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {row['category']}")
    print(f"üè¢ –°—É–±—ä–µ–∫—Ç: {row['subject_name']}")
    print("‚îÄ" * 70)
    print(f"   –ò—Å—Ç–∏–Ω–Ω–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:     {true_label}")
    print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {pred_label} {status}")
    print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: –Ω–µ–≥–∞—Ç–∏–≤={pred_probs[0]*100:.1f}%, "
          f"–Ω–µ–π—Ç—Ä–∞–ª—å={pred_probs[1]*100:.1f}%, –ø–æ–∑–∏—Ç–∏–≤={pred_probs[2]*100:.1f}%")
    print("‚îÄ" * 70)
    print(f"   –ò—Å—Ç–∏–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å —Ä–µ–ø—É—Ç–∞—Ü–∏–∏:     {row['reputation_index']:+.3f}")
    print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å:          {pred_index:+.3f}")
    print(f"   –û—à–∏–±–∫–∞ (|—Ä–∞–∑–Ω–∏—Ü–∞|):            {abs(row['reputation_index'] - pred_index):.3f}")
    
    return is_correct


def main():
    parser = argparse.ArgumentParser(description="–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö")
    parser.add_argument("-n", "--num", type=int, default=5, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤")
    parser.add_argument("--errors", action="store_true", help="–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ—à–∏–±–∫–∏")
    parser.add_argument("--class", dest="target_class", type=int, choices=[0, 1, 2],
                        help="–§–∏–ª—å—Ç—Ä –ø–æ –∫–ª–∞—Å—Å—É (0=–Ω–µ–≥–∞—Ç–∏–≤, 1=–Ω–µ–π—Ç—Ä–∞–ª—å, 2=–ø–æ–∑–∏—Ç–∏–≤)")
    parser.add_argument("--seed", type=int, default=None, help="Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏")
    args = parser.parse_args()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞
    model, preprocessor = load_model_and_preprocessor()
    test_df = get_test_data(preprocessor)
    
    print(f"\nüìä –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(test_df)}")
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–ª–∞—Å—Å—É
    if args.target_class is not None:
        test_df = test_df[test_df["sentiment_class"] == args.target_class]
        labels = ["–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö", "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö", "–ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö"]
        print(f"   –§–∏–ª—å—Ç—Ä: —Ç–æ–ª—å–∫–æ {labels[args.target_class]} ({len(test_df)} —à—Ç.)")
    
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ seed
    if args.seed:
        np.random.seed(args.seed)
    
    # –í—ã–±–æ—Ä –ø—Ä–∏–º–µ—Ä–æ–≤
    if args.errors:
        # –†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ –æ—à–∏–±–æ–∫ ‚Äî –ø—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—à–∏–±–∫–∏
        print("\nüîç –ü–æ–∏—Å–∫ –æ—à–∏–±–æ—á–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")
        errors_found = 0
        
        for idx, row in test_df.iterrows():
            pred_probs, pred_index = predict_single(
                model, preprocessor,
                row["review_text"], row["rating"], row["category"]
            )
            pred_class = np.argmax(pred_probs)
            
            if pred_class != row["sentiment_class"]:
                display_prediction(row, pred_class, pred_probs, pred_index)
                errors_found += 1
                
                if errors_found >= args.num:
                    break
        
        if errors_found == 0:
            print("‚úÖ –û—à–∏–±–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
        else:
            print(f"\nüìà –ù–∞–π–¥–µ–Ω–æ –æ—à–∏–±–æ–∫: {errors_found}")
    else:
        # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º ‚Äî —Å–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
        samples = test_df.sample(n=min(args.num, len(test_df)))
        
        correct = 0
        total_mae = 0
        
        print(f"\nüé≤ –°–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏:")
        
        for idx, row in samples.iterrows():
            pred_probs, pred_index = predict_single(
                model, preprocessor,
                row["review_text"], row["rating"], row["category"]
            )
            pred_class = np.argmax(pred_probs)
            
            is_correct = display_prediction(row, pred_class, pred_probs, pred_index)
            if is_correct:
                correct += 1
            total_mae += abs(row["reputation_index"] - pred_index)
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("\n" + "‚ïê" * 70)
        print(f"üìä –ò–¢–û–ì–û –ø–æ {len(samples)} –ø—Ä–∏–º–µ—Ä–∞–º:")
        print(f"   –¢–æ—á–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {correct}/{len(samples)} ({correct/len(samples)*100:.1f}%)")
        print(f"   –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ (MAE): {total_mae/len(samples):.3f}")
        print("‚ïê" * 70)


if __name__ == "__main__":
    main()
