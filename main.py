"""
–ì–ª–∞–≤–Ω—ã–π –º–æ–¥—É–ª—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ-–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–π —Å–∏—Å—Ç–µ–º—ã
–∞–Ω–∞–ª–∏–∑–∞ –≤–ª–∏—è–Ω–∏—è –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Ä–µ–ø—É—Ç–∞—Ü–∏—é

–ó–∞–ø—É—Å–∫:
    python main.py --generate   # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞
    python main.py --train      # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    python main.py --analyze    # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞
    python main.py --full       # –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω
    python main.py --demo       # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
"""

import argparse
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent / "src"))

from config import DATA_DIR, MODELS_DIR, LOGS_DIR


def generate_dataset():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    print("\n" + "="*60)
    print("üìù –ì–ï–ù–ï–†–ê–¶–ò–Ø –°–ò–ù–¢–ï–¢–ò–ß–ï–°–ö–û–ì–û –î–ê–¢–ê–°–ï–¢–ê")
    print("="*60)
    
    from src.data_generator import ReviewDataGenerator
    
    generator = ReviewDataGenerator()
    df = generator.generate_dataset()
    generator.save_dataset(df)
    
    print("\nüìä –ü—Ä–∏–º–µ—Ä—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤:")
    for i, row in df.head(3).iterrows():
        print(f"\n   [{row['subject_name']}] –û—Ü–µ–Ω–∫–∞: {row['rating']}/5")
        print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {row['category']}")
        print(f"   –¢–µ–∫—Å—Ç: {row['review_text'][:80]}...")
        labels = ["–Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è", "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è", "–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è"]
        print(f"   –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {labels[row['sentiment_class']]}, –ò–Ω–¥–µ–∫—Å: {row['reputation_index']:.2f}")


def train_model():
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    print("\n" + "="*60)
    print("üöÄ –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò")
    print("="*60)
    
    from src.training import ModelTrainer
    
    trainer = ModelTrainer()
    df = trainer.load_data()
    train_df, val_df, test_df = trainer.split_data(df)
    data = trainer.prepare_data(train_df, val_df, test_df)
    trainer.train(data)
    metrics = trainer.evaluate(data)
    trainer.plot_training_history()
    trainer.plot_confusion_matrix(data)
    trainer.save_artifacts()
    
    return metrics


def run_analytics():
    """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
    print("\n" + "="*60)
    print("üìä –ê–ù–ê–õ–ò–¢–ò–ö–ê –†–ï–ü–£–¢–ê–¶–ò–ò")
    print("="*60)
    
    import pandas as pd
    from src.analytics import ReputationAnalytics
    
    analytics = ReputationAnalytics()
    df = pd.read_csv(DATA_DIR / "synthetic_dataset.csv")
    
    report = analytics.generate_report(df)
    print(report)
    
    analytics.plot_reputation_distribution(df)
    analytics.plot_subject_comparison(df)
    
    with open(LOGS_DIR / "analytics_report.txt", "w", encoding="utf-8") as f:
        f.write(report)


def demo_predictions():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ –Ω–æ–≤—ã—Ö –æ—Ç–∑—ã–≤–∞—Ö"""
    print("\n" + "="*60)
    print("üîÆ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô")
    print("="*60)
    
    from src.analytics import ReputationAnalytics
    import numpy as np
    
    analytics = ReputationAnalytics()
    analytics.load_model()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –æ—Ç–∑—ã–≤—ã
    test_reviews = [
        ("–û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä! –ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ–µ, –¥–æ—Å—Ç–∞–≤–∫–∞ –±—ã—Å—Ç—Ä–∞—è.", 5, "–≠–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞"),
        ("–ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é. –°–ª–æ–º–∞–ª—Å—è —á–µ—Ä–µ–∑ –Ω–µ–¥–µ–ª—é, –¥–µ–Ω—å–≥–∏ –Ω–µ –≤–µ—Ä–Ω—É–ª–∏.", 1, "–ë—ã—Ç–æ–≤–∞—è —Ç–µ—Ö–Ω–∏–∫–∞"),
        ("–ù–æ—Ä–º–∞–ª—å–Ω–æ, –Ω–∏—á–µ–≥–æ –æ—Å–æ–±–µ–Ω–Ω–æ–≥–æ. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ü–µ–Ω–µ.", 3, "–û–¥–µ–∂–¥–∞"),
    ]
    
    texts = [r[0] for r in test_reviews]
    ratings = [r[1] for r in test_reviews]
    categories = [r[2] for r in test_reviews]
    
    class_probs, rep_indices = analytics.predict_reputation(texts, ratings, categories)
    
    labels = ["–Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è", "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è", "–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è"]
    print("\nüìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:")
    for i, (text, rating, cat) in enumerate(test_reviews):
        pred_class = np.argmax(class_probs[i])
        confidence = class_probs[i][pred_class] * 100
        
        print(f"\n{'‚îÄ'*50}")
        print(f"–¢–µ–∫—Å—Ç: {text[:60]}...")
        print(f"–û—Ü–µ–Ω–∫–∞: {rating}/5, –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {cat}")
        print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {labels[pred_class]} ({confidence:.1f}%)")
        print(f"–ò–Ω–¥–µ–∫—Å —Ä–µ–ø—É—Ç–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –≤–ª–∏—è–Ω–∏—è: {rep_indices[i]:.3f}")


def main():
    parser = argparse.ArgumentParser(
        description="–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ-–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–ø—É—Ç–∞—Ü–∏–∏"
    )
    parser.add_argument("--generate", action="store_true", help="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞")
    parser.add_argument("--train", action="store_true", help="–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    parser.add_argument("--analyze", action="store_true", help="–ê–Ω–∞–ª–∏—Ç–∏–∫–∞")
    parser.add_argument("--demo", action="store_true", help="–î–µ–º–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
    parser.add_argument("--full", action="store_true", help="–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω")
    
    args = parser.parse_args()
    
    if args.full or (not any([args.generate, args.train, args.analyze, args.demo])):
        generate_dataset()
        train_model()
        run_analytics()
        demo_predictions()
    else:
        if args.generate:
            generate_dataset()
        if args.train:
            train_model()
        if args.analyze:
            run_analytics()
        if args.demo:
            demo_predictions()
    
    print("\n‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")


if __name__ == "__main__":
    main()
